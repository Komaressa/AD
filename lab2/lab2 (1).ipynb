{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: ipython in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from ipython) (4.13.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from stack_data->ipython) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from stack_data->ipython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from stack_data->ipython) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas matplotlib ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завдання 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для кожної із адміністративних одиниць України завантажити тестові структуровані файли, що містять значення VHI-індексу. \n",
    "Ця процедура має бути автоматизована, параметром процедури має бути індекс (номер) області. \n",
    "При зберіганні файлу до його імені потрібно додати дату та час завантаження.\n",
    "\n",
    "Передбачити повторні запуски скрипту, довантаження нових даних та колізію\n",
    "даних;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Дублікат виявлено. Файл не збережено.\n",
      "[2] Дублікат виявлено. Файл не збережено.\n",
      "[3] Дублікат виявлено. Файл не збережено.\n",
      "[4] Дублікат виявлено. Файл не збережено.\n",
      "[5] Дублікат виявлено. Файл не збережено.\n",
      "[6] Дублікат виявлено. Файл не збережено.\n",
      "[7] Дублікат виявлено. Файл не збережено.\n",
      "[8] Дублікат виявлено. Файл не збережено.\n",
      "[9] Дублікат виявлено. Файл не збережено.\n",
      "[10] Дублікат виявлено. Файл не збережено.\n",
      "[11] Дублікат виявлено. Файл не збережено.\n",
      "[12] Дублікат виявлено. Файл не збережено.\n",
      "[13] Дублікат виявлено. Файл не збережено.\n",
      "[14] Дублікат виявлено. Файл не збережено.\n",
      "[15] Дублікат виявлено. Файл не збережено.\n",
      "[16] Дублікат виявлено. Файл не збережено.\n",
      "[17] Дублікат виявлено. Файл не збережено.\n",
      "[18] Дублікат виявлено. Файл не збережено.\n",
      "[19] Дублікат виявлено. Файл не збережено.\n",
      "[20] Дублікат виявлено. Файл не збережено.\n",
      "[21] Дублікат виявлено. Файл не збережено.\n",
      "[22] Дублікат виявлено. Файл не збережено.\n",
      "[23] Дублікат виявлено. Файл не збережено.\n",
      "[24] Дублікат виявлено. Файл не збережено.\n",
      "[25] Дублікат виявлено. Файл не збережено.\n",
      "[26] Дублікат виявлено. Файл не збережено.\n",
      "[27] Дублікат виявлено. Файл не збережено.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import hashlib\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Папка для збереження файлів\n",
    "FOLDER_NAME = \"vhi_data\"\n",
    "os.makedirs(FOLDER_NAME, exist_ok=True)\n",
    "\n",
    "def get_timestamp():\n",
    "    \"\"\"Повертає поточну дату та час у вигляді рядка.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "def build_filename(region_id):\n",
    "    \"\"\"Створює ім’я файлу для збереження.\"\"\"\n",
    "    return os.path.join(FOLDER_NAME, f\"VHI_region_{region_id}_{get_timestamp()}.csv\")\n",
    "\n",
    "def hash_file(filepath):\n",
    "    \"\"\"Обчислює SHA-256 хеш для вказаного файлу.\"\"\"\n",
    "    hasher = hashlib.sha256()\n",
    "    with open(filepath, 'rb') as file:\n",
    "        for block in iter(lambda: file.read(8192), b''):\n",
    "            hasher.update(block)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def is_duplicate(new_file, region_id):\n",
    "    \"\"\"Перевіряє, чи вже існує файл з ідентичним вмістом.\"\"\"\n",
    "    new_hash = hash_file(new_file)\n",
    "    for fname in os.listdir(FOLDER_NAME):\n",
    "        full_path = os.path.join(FOLDER_NAME, fname)\n",
    "        if fname.endswith(\".csv\") and f\"region_{region_id}_\" in fname and full_path != new_file:\n",
    "            if hash_file(full_path) == new_hash:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def download_vhi(region_id):\n",
    "    \"\"\"Завантажує VHI-дані для області.\"\"\"\n",
    "    url = (\n",
    "        f\"https://www.star.nesdis.noaa.gov/smcd/emb/vci/VH/get_TS_admin.php?\"\n",
    "        f\"country=UKR&provinceID={region_id}&year1=1981&year2=2024&type=Mean\"\n",
    "    )\n",
    "    file_path = build_filename(region_id)\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            content_type = response.getheader(\"Content-Type\", \"\")\n",
    "            if \"text\" not in content_type and \"csv\" not in content_type:\n",
    "                print(f\"[{region_id}] Помилка: невірний формат відповіді ({content_type}).\")\n",
    "                return\n",
    "\n",
    "            data = response.read()\n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(data)\n",
    "\n",
    "        if is_duplicate(file_path, region_id):\n",
    "            os.remove(file_path)\n",
    "            print(f\"[{region_id}] Дублікат виявлено. Файл не збережено.\")\n",
    "        else:\n",
    "            print(f\"[{region_id}] Новий файл збережено: {os.path.basename(file_path)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{region_id}] Помилка завантаження: {e}\")\n",
    "\n",
    "# Завантаження даних для всіх 27 регіонів України\n",
    "for region in range(1, 28):\n",
    "    download_vhi(region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завдання 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зчитати завантажені текстові файли у фрейм\n",
    "(https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) (детальніше\n",
    "про роботу із фреймами буде розказано у подальших лабораторних роботах).\n",
    "Імена стовбців фрейму мають бути змістовними та легкими для сприйняття (не\n",
    "повинно бути спеціалізованих символів, пробілів тощо). Ця задача має бути\n",
    "реалізована у вигляді окремої процедури, яка на вхід приймає шлях до\n",
    "директорії, в якій зберігаються файли;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7228\\455160447.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_data = pd.concat([combined_data, df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Об'єднані дані успішно збережено у full.csv\n",
      "Перші 10 рядків:\n",
      "   Year Week    SMN     SMT    VCI    TCI    VHI PROVINCE_ID\n",
      "0  1982    1  0.053  260.31  45.01  39.46  42.23           1\n",
      "1  1982    2  0.054  262.29  46.83  31.75  39.29           1\n",
      "2  1982    3  0.055  263.82  48.13  27.24  37.68           1\n",
      "3  1982    4  0.053  265.33  46.09  23.91  35.00           1\n",
      "4  1982    5  0.050  265.66  41.46  26.65  34.06           1\n",
      "5  1982    6  0.048  266.55  36.56  29.46  33.01           1\n",
      "6  1982    7  0.048  267.84  32.17  31.14  31.65           1\n",
      "7  1982    8  0.050  269.30  30.30  32.50  31.40           1\n",
      "8  1982    9  0.052  270.75  28.23  35.22  31.73           1\n",
      "9  1982   10  0.056  272.73  25.25  37.63  31.44           1\n",
      "Останні 10 рядків:\n",
      "       Year Week    SMN     SMT    VCI    TCI    VHI PROVINCE_ID\n",
      "59012  2024   43  0.259  281.45  79.71  17.45  48.58          27\n",
      "59013  2024   44  0.229  279.41  76.74  13.33  45.04          27\n",
      "59014  2024   45  0.206  278.07  77.64   8.70  43.17          27\n",
      "59015  2024   46  0.177  275.95  74.84  10.23  42.53          27\n",
      "59016  2024   47  0.149  273.20  71.22  16.89  44.05          27\n",
      "59017  2024   48  0.128  270.55  64.97  25.53  45.25          27\n",
      "59018  2024   49  0.115  269.06  60.12  27.24  43.68          27\n",
      "59019  2024   50  0.104  267.75  55.24  25.89  40.57          27\n",
      "59020  2024   51  0.094  266.45  51.16  24.29  37.72          27\n",
      "59021  2024   52  0.093  266.38  54.22  21.11  37.66          27\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Папка з CSV-файлами та вихідний файл\n",
    "FOLDER_NAME = \"vhi_data\"  # Моя директорія\n",
    "output_path = \"full.csv\" # Файл для збереження \n",
    "\n",
    "# Імена колонок для зчитування\n",
    "COLUMN_NAMES = [\"Year\", \"Week\", \"SMN\", \"SMT\", \"VCI\", \"TCI\", \"VHI\", \"PROVINCE_ID\"]\n",
    "\n",
    "# Порожній DataFrame для об'єднання даних\n",
    "combined_data = pd.DataFrame(columns=COLUMN_NAMES)\n",
    "\n",
    "# Отримуємо список CSV-файлів, відсортованих за номером області\n",
    "files = sorted([f for f in os.listdir(FOLDER_NAME) if f.endswith('.csv')], \n",
    "               key=lambda x: int(re.findall(r'\\d+', x)[0]))\n",
    "\n",
    "# Обробка кожного файлу\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(FOLDER_NAME, file_name)\n",
    "\n",
    "    try:\n",
    "        # Отримуємо ID області з назви файлу\n",
    "        province_id = int(re.findall(r'\\d+', file_name)[0])\n",
    "\n",
    "        # Зчитуємо файл, пропускаючи перші 2 рядки\n",
    "        df = pd.read_csv(file_path, skiprows=2, names=COLUMN_NAMES)\n",
    "\n",
    "        # Видаляємо HTML-теги з Year\n",
    "        df[\"Year\"] = df[\"Year\"].astype(str).str.replace(r'<tt><pre>|</pre></tt>', '', regex=True)\n",
    "\n",
    "        # pd.to_numeric(..., errors='coerce') замінює некоректні значення на NaN, якщо такі є.\n",
    "        df[\"Year\"] = pd.to_numeric(df[\"Year\"], errors='coerce')\n",
    "        df[\"Week\"] = pd.to_numeric(df[\"Week\"], errors='coerce')\n",
    "\n",
    "        # Видаляє рядки з NaN у Year та Week, щоб уникнути помилок при подальших обчисленнях\n",
    "        df.dropna(subset=[\"Year\", \"Week\"], inplace=True)\n",
    "\n",
    "        # Перетворює Year і Week на цілі числа (int):\n",
    "        df[\"Year\"] = df[\"Year\"].astype(int)\n",
    "        df[\"Week\"] = df[\"Week\"].astype(int)\n",
    "\n",
    "        # Додаємо ID області у колонку \"PROVINCE_ID\"\n",
    "        df[\"PROVINCE_ID\"] = province_id\n",
    "\n",
    "        # Видаляємо рядки з некоректними VHI та NaN\n",
    "        df = df[df[\"VHI\"] != -1].dropna()\n",
    "\n",
    "        # Додаємо оброблені дані в загальний DataFrame\n",
    "        combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Помилка при читанні файлу {file_name}: {e}\")\n",
    "\n",
    "# Зберігаємо результат у файл\n",
    "combined_data.to_csv(output_path, index=False)\n",
    "\n",
    "# Виводимо перші 10 рядків\n",
    "print(\"Об'єднані дані успішно збережено у\", output_path)\n",
    "print(\"Перші 10 рядків:\")\n",
    "print(combined_data.head(10))\n",
    "print(\"Останні 10 рядків:\")\n",
    "print(combined_data.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завдання 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реалізувати окрему процедуру, яка змінить індекси областей, які використані на\n",
    "порталі NOAA (за англійською абеткою) на наступні, за українською (виключно\n",
    "старі індекси на нові):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оновлений файл збережено: Updated_Provinces.csv\n",
      "   Year Week    SMN     SMT    VCI    TCI    VHI  PROVINCE_ID\n",
      "0  1982    1  0.053  260.31  45.01  39.46  42.23           21\n",
      "1  1982    2  0.054  262.29  46.83  31.75  39.29           21\n",
      "2  1982    3  0.055  263.82  48.13  27.24  37.68           21\n",
      "3  1982    4  0.053  265.33  46.09  23.91  35.00           21\n",
      "4  1982    5  0.050  265.66  41.46  26.65  34.06           21\n",
      "5  1982    6  0.048  266.55  36.56  29.46  33.01           21\n",
      "6  1982    7  0.048  267.84  32.17  31.14  31.65           21\n",
      "7  1982    8  0.050  269.30  30.30  32.50  31.40           21\n",
      "8  1982    9  0.052  270.75  28.23  35.22  31.73           21\n",
      "9  1982   10  0.056  272.73  25.25  37.63  31.44           21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def update_province_ids(df):\n",
    "    \n",
    "    province_mapping = {\n",
    "        1: 21,  2: 26,  3: 25,  4: 27,  5: 3,   6: 4,   7: 8,  \n",
    "        8: 24,  9: 22, 10: 23, 11: 10, 12: 9,  13: 11, 14: 12, \n",
    "       15: 13, 16: 14, 17: 15, 18: 16, 19: 17, 20: 18, 21: 19, \n",
    "       22: 20, 23: 6,  24: 1,  25: 2,  26: 7,  27: 5\n",
    "    }\n",
    "\n",
    "    # Переконуємося, що колонка \"PROVINCE_ID\" є у DataFrame\n",
    "    if \"PROVINCE_ID\" not in df.columns:\n",
    "        print(\"Колонка 'PROVINCE_ID' не знайдена у DataFrame!\")\n",
    "        return df\n",
    "\n",
    "    # Оновлення значень\n",
    "    df[\"PROVINCE_ID\"] = df[\"PROVINCE_ID\"].map(province_mapping)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Оновлення індексів у `combined_data`\n",
    "combined_data = update_province_ids(combined_data)\n",
    "\n",
    "# Збереження у файл\n",
    "output_file = \"Updated_Provinces.csv\"\n",
    "combined_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Вивід результату\n",
    "print(f\"Оновлений файл збережено: {output_file}\")\n",
    "print(combined_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Завдання 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реалізувати процедури для формування вибірок наступного виду (включаючи елементи аналізу):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o Ряд VHI для області за вказаний рік;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Отримати ряд VHI для області за вказаний рік"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year Week    VHI\n",
      "30500  2023    1  55.95\n",
      "30501  2023    2  55.76\n",
      "30502  2023    3  53.30\n",
      "30503  2023    4  51.69\n",
      "30504  2023    5  47.30\n",
      "30505  2023    6  42.82\n",
      "30506  2023    7  40.70\n",
      "30507  2023    8  41.41\n",
      "30508  2023    9  41.99\n",
      "30509  2023   10  42.99\n",
      "30510  2023   11  44.72\n",
      "30511  2023   12  45.52\n",
      "30512  2023   13  46.63\n",
      "30513  2023   14  47.74\n",
      "30514  2023   15  49.49\n",
      "30515  2023   16  52.18\n",
      "30516  2023   17  56.36\n",
      "30517  2023   18  62.75\n",
      "30518  2023   19  67.23\n",
      "30519  2023   20  69.22\n",
      "30520  2023   21  70.63\n",
      "30521  2023   22  69.15\n",
      "30522  2023   23  70.39\n",
      "30523  2023   24  72.79\n",
      "30524  2023   25  73.59\n",
      "30525  2023   26  74.27\n",
      "30526  2023   27  72.19\n",
      "30527  2023   28  71.05\n",
      "30528  2023   29  70.08\n",
      "30529  2023   30  68.86\n",
      "30530  2023   31  68.12\n",
      "30531  2023   32  66.47\n",
      "30532  2023   33  61.78\n",
      "30533  2023   34  57.71\n",
      "30534  2023   35  55.31\n",
      "30535  2023   36  50.18\n",
      "30536  2023   37  44.03\n",
      "30537  2023   38  40.90\n",
      "30538  2023   39  39.09\n",
      "30539  2023   40  37.51\n",
      "30540  2023   41  35.94\n",
      "30541  2023   42  33.38\n",
      "30542  2023   43  32.78\n",
      "30543  2023   44  31.04\n",
      "30544  2023   45  32.32\n",
      "30545  2023   46  33.30\n",
      "30546  2023   47  34.47\n",
      "30547  2023   48  36.13\n",
      "30548  2023   49  35.84\n",
      "30549  2023   50  36.31\n",
      "30550  2023   51  38.67\n",
      "30551  2023   52  43.31\n"
     ]
    }
   ],
   "source": [
    "def get_vhi_for_region_year(df, province_id, year):\n",
    "\n",
    "    return df[(df[\"PROVINCE_ID\"] == province_id) & (df[\"Year\"] == year)][[\"Year\", \"Week\", \"VHI\"]]\n",
    "\n",
    "vhi_data = get_vhi_for_region_year(combined_data, province_id=12, year=2023)\n",
    "print(vhi_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Пошук екстремумів (min, max), середнього, медіани"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PROVINCE_ID  Year    min    max       mean  median\n",
      "0            5  2000  27.46  66.30  47.882885  47.375\n",
      "1            5  2023  32.92  64.08  48.268846  47.890\n",
      "2           10  2000  10.60  61.87  39.758269  35.915\n",
      "3           10  2023  31.55  65.72  46.665385  46.260\n"
     ]
    }
   ],
   "source": [
    "def get_vhi_statistics(df, province_ids, years):\n",
    "\n",
    "    # Фільтруємо дані за обраними областями та роками\n",
    "    filtered_df = df[(df[\"PROVINCE_ID\"].isin(province_ids)) & (df[\"Year\"].isin(years))]\n",
    "\n",
    "    # Групуємо за областю та роком, обчислюємо статистичні показники\n",
    "    return filtered_df.groupby([\"PROVINCE_ID\", \"Year\"])[\"VHI\"].agg([\"min\", \"max\", \"mean\", \"median\"]).reset_index()\n",
    "\n",
    "# Виклик функції для областей з ID 5 і 10 у 2000 та 2020 роках\n",
    "stats = get_vhi_statistics(combined_data, province_ids=[5, 10], years=[2000, 2023])\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Отримати ряд VHI за вказаний діапазон років для вказаних областей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year Week  PROVINCE_ID    VHI\n",
      "10150  2010    1            3  52.08\n",
      "10151  2010    2            3  49.75\n",
      "10152  2010    3            3  48.82\n",
      "10153  2010    4            3  48.13\n",
      "10154  2010    5            3  46.79\n",
      "...     ...  ...          ...    ...\n",
      "56779  2023   48            7  34.82\n",
      "56780  2023   49            7  35.22\n",
      "56781  2023   50            7  35.57\n",
      "56782  2023   51            7  36.56\n",
      "56783  2023   52            7  37.99\n",
      "\n",
      "[2184 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_vhi_by_year_range(df, province_ids, start_year, end_year):\n",
    "\n",
    "    result = df[(df[\"PROVINCE_ID\"].isin(province_ids)) & (df[\"Year\"].between(start_year, end_year))]\n",
    "    \n",
    "    if result.empty:\n",
    "        print(\"Дані для вказаного діапазону відсутні!\")\n",
    "    \n",
    "    return result[[\"Year\", \"Week\", \"PROVINCE_ID\", \"VHI\"]]\n",
    "\n",
    "# Використання:\n",
    "province_ids = [3, 7, 12]  # Введи потрібні області\n",
    "start_year = 2010  # Початковий рік\n",
    "end_year = 2023  # Кінцевий рік\n",
    "vhi_range_data = get_vhi_by_year_range(combined_data, province_ids, start_year, end_year)\n",
    "print(vhi_range_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o Для всього набору даних виявити роки, протягом яких екстремальні\n",
    "посухи торкнулися більше вказаного відсотка областей по Україні (20%\n",
    "областей - 5 областей з 25). Повернути роки, назви областей з\n",
    "екстремальними посухами та значення VHI;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Виявити роки, коли посуха торкнулася >20% областей (VHI < 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year  PROVINCE_ID    VHI\n",
      "949    2000           21  14.64\n",
      "950    2000           21  11.82\n",
      "951    2000           21  10.81\n",
      "952    2000           21  10.68\n",
      "953    2000           21  12.30\n",
      "...     ...          ...    ...\n",
      "55932  2007            7  11.55\n",
      "55933  2007            7  10.88\n",
      "55934  2007            7  11.06\n",
      "55935  2007            7  12.05\n",
      "55936  2007            7  13.84\n",
      "\n",
      "[88 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def find_drought_years(df, threshold=15, affected_percentage=0.2):\n",
    "\n",
    "    province_count = df[\"PROVINCE_ID\"].nunique()  # Загальна кількість областей\n",
    "    min_affected = int(province_count * affected_percentage)  # Мінімальна кількість уражених областей\n",
    "\n",
    "    drought_data = df[df[\"VHI\"] < threshold].groupby([\"Year\"])[\"PROVINCE_ID\"].nunique().reset_index()\n",
    "    drought_years = drought_data[drought_data[\"PROVINCE_ID\"] >= min_affected]\n",
    "\n",
    "    if drought_years.empty:\n",
    "        print(\"Не знайдено років, коли посуха торкнулася 20% областей.\")\n",
    "        return None\n",
    "\n",
    "    # Отримуємо детальні дані про області, які потрапили під посуху\n",
    "    drought_details = df[(df[\"Year\"].isin(drought_years[\"Year\"])) & (df[\"VHI\"] < threshold)]\n",
    "    \n",
    "    return drought_details[[\"Year\", \"PROVINCE_ID\", \"VHI\"]]\n",
    "\n",
    "# Використання:\n",
    "drought_info = find_drought_years(combined_data)\n",
    "print(drought_info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
